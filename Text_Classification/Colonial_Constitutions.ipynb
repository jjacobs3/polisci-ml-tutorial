{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long story short, in this tutorial we're going to use ML to try and predict whether or not a given constitution was written by a former UK colony. The idea is loosely inspired by the paper [\"Constitutional Islamization and Human Rights: The Surprising Origin and Spread of Islamic Supremacy in Constitutions\"](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2438983) (Ahmed and Ginsberg 2014). For example, that paper codes countries as 1=former UK colony and 0=otherwise, as we'll do here.\n",
    "\n",
    "The data on colonization is from http://www.cepii.fr/PDF_PUB/wp/2011/wp2011-25.pdf, and the corpus of constitutions is from https://www.poltext.org/en/constitutional-texts. Let's get to it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm basically starting from scratch here, just so that it's completely transparent (I'm not sweeping anything under the rug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using os to get list of files in a directory\n",
    "import os\n",
    "# Using pandas for its DataFrame structure, which lets us maintain a \"spreadsheet\" of the data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all files in the \"constitutions\" directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_files = sorted(os.listdir('constitutions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the colonization dataset as a Pandas DataFrame. Note that it lets you load Stata .dta files via the `pd.read_stata()` function, and figures out all the variable names, converstion, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_colonial_df = pd.read_stata('geo_cepii.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.head(n)` function lets you look at the first `n` rows of a DataFrame, with 5 rows as the default, so we'll use it throughout to examine what our DataFrames look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>cnum</th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>area</th>\n",
       "      <th>dis_int</th>\n",
       "      <th>landlocked</th>\n",
       "      <th>continent</th>\n",
       "      <th>city_en</th>\n",
       "      <th>...</th>\n",
       "      <th>lang9_2</th>\n",
       "      <th>lang9_3</th>\n",
       "      <th>lang9_4</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>colonizer2</th>\n",
       "      <th>colonizer3</th>\n",
       "      <th>colonizer4</th>\n",
       "      <th>short_colonizer1</th>\n",
       "      <th>short_colonizer2</th>\n",
       "      <th>short_colonizer3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorre</td>\n",
       "      <td>453</td>\n",
       "      <td>8.005398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Emirats arabes unis</td>\n",
       "      <td>83657</td>\n",
       "      <td>108.788994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GBR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>652225</td>\n",
       "      <td>303.761353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>...</td>\n",
       "      <td>Uzbek</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GBR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>ATG</td>\n",
       "      <td>28</td>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>Antigua-et-Barbuda</td>\n",
       "      <td>442</td>\n",
       "      <td>7.907605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>America</td>\n",
       "      <td>Saint John's</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GBR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI</td>\n",
       "      <td>AIA</td>\n",
       "      <td>660</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>102</td>\n",
       "      <td>3.798690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>America</td>\n",
       "      <td>The Valley</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GBR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso2 iso3  cnum               country                 pays    area  \\\n",
       "0   AD  AND    20               Andorra              Andorre     453   \n",
       "1   AE  ARE   784  United Arab Emirates  Emirats arabes unis   83657   \n",
       "2   AF  AFG     4           Afghanistan          Afghanistan  652225   \n",
       "3   AG  ATG    28   Antigua and Barbuda   Antigua-et-Barbuda     442   \n",
       "4   AI  AIA   660              Anguilla             Anguilla     102   \n",
       "\n",
       "      dis_int  landlocked continent           city_en       ...         \\\n",
       "0    8.005398         0.0    Europe  Andorra la Vella       ...          \n",
       "1  108.788994         0.0      Asia         Abu Dhabi       ...          \n",
       "2  303.761353         1.0      Asia             Kabul       ...          \n",
       "3    7.907605         0.0   America      Saint John's       ...          \n",
       "4    3.798690         0.0   America        The Valley       ...          \n",
       "\n",
       "  lang9_2  lang9_3  lang9_4  colonizer1  colonizer2  colonizer3 colonizer4  \\\n",
       "0                                                                            \n",
       "1                                   GBR                                      \n",
       "2   Uzbek                                                                    \n",
       "3                                   GBR                                      \n",
       "4                                   GBR                                      \n",
       "\n",
       "  short_colonizer1 short_colonizer2 short_colonizer3  \n",
       "0                                                     \n",
       "1                                                     \n",
       "2              GBR                                    \n",
       "3                                                     \n",
       "4                                                     \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_colonial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of the 34 variables in the full DataFrame, we'll work with a reduced DataFrame with just the three variables we need: `country` (English-language name of country), `pays` (French-language name of country, for merging), and `colonizer1` (the \"primary\" colonizer of the country, if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonial_df = full_colonial_df[[\"country\",\"pays\",\"colonizer1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorre</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>Antigua-et-Barbuda</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country                 pays colonizer1\n",
       "0               Andorra              Andorre           \n",
       "1  United Arab Emirates  Emirats arabes unis        GBR\n",
       "2           Afghanistan          Afghanistan           \n",
       "3   Antigua and Barbuda   Antigua-et-Barbuda        GBR\n",
       "4              Anguilla             Anguilla        GBR"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colonial_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have two separate pieces of information here, the first being the colonization dataset and the second being the list of constitution .txt files, we need to figure out which row in the colonization data corresponds to which constitution .txt file, via merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now we just have a (Python) list of filenames, so we convert that to a Pandas DataFrame here as a first step towards merging with the Pandas DataFrame containing the colonization info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = pd.DataFrame(const_files, columns=[\"filename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algerie1989-2008.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allemagne1949-2010.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andorre1993.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename\n",
       "0     afghanistan2004.txt\n",
       "1    albanie1998-2008.txt\n",
       "2    algerie1989-2008.txt\n",
       "3  allemagne1949-2010.txt\n",
       "4         andorre1993.txt"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we process the raw filenames to extract just a string with the (lowercased) country names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \".txt\"\n",
    "file_df[\"file_country\"] = file_df[\"filename\"].str.replace(\".txt\",\"\")\n",
    "# Replace \"-\" with \" \"\n",
    "file_df[\"file_country\"] = file_df[\"file_country\"].str.replace(\"-\",\" \")\n",
    "# Replace \"_\" with \" \"\n",
    "file_df[\"file_country\"] = file_df[\"file_country\"].str.replace(\"_\",\" \")\n",
    "# Remove digits (the years)\n",
    "file_df[\"file_country\"] = file_df[\"file_country\"].str.replace(\"\\d\",\"\")\n",
    "# Remove trailing whitespace\n",
    "file_df[\"file_country\"] = file_df[\"file_country\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algerie1989-2008.txt</td>\n",
       "      <td>algerie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allemagne1949-2010.txt</td>\n",
       "      <td>allemagne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 filename file_country\n",
       "0     afghanistan2004.txt  afghanistan\n",
       "1    albanie1998-2008.txt      albanie\n",
       "2    algerie1989-2008.txt      algerie\n",
       "3  allemagne1949-2010.txt    allemagne\n",
       "4         andorre1993.txt      andorre"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've successfully extracted the (lowercased) country names from the filenames. Now we lowercase the country names in the *colonization* dataset (`colonial_df`), so that Pandas will be able to match them successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "colonial_df[\"pays\"] = colonial_df[\"pays\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax here is like: `merged_df = left_dataset.merge(right_dataset, left_on=<left key variable>, right_on=<right key variable>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = colonial_df.merge(file_df, left_on=\"pays\", right_on=\"file_country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get some duplicates because some countries have more than one constitution in the dataset. For the sake of this tutorial we just pick the first constitution and move on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "merged_df = merged_df.drop_duplicates(subset=\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorre</td>\n",
       "      <td></td>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "      <td>emirats-arabes-unis1971-1972.txt</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albanie</td>\n",
       "      <td>TUR</td>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>angola</td>\n",
       "      <td>PRT</td>\n",
       "      <td>angola2010.txt</td>\n",
       "      <td>angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>argentine</td>\n",
       "      <td>ESP</td>\n",
       "      <td>argentine1853-1994.txt</td>\n",
       "      <td>argentine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austria</td>\n",
       "      <td>autriche</td>\n",
       "      <td></td>\n",
       "      <td>autriche1920.txt</td>\n",
       "      <td>autriche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Australia</td>\n",
       "      <td>australie</td>\n",
       "      <td>GBR</td>\n",
       "      <td>australie1900-1977.txt</td>\n",
       "      <td>australie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>barbade</td>\n",
       "      <td>GBR</td>\n",
       "      <td>barbade1966-2007.txt</td>\n",
       "      <td>barbade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>GBR</td>\n",
       "      <td>bangladesh1972-2011.txt</td>\n",
       "      <td>bangladesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country                 pays colonizer1  \\\n",
       "0                Andorra              andorre              \n",
       "1   United Arab Emirates  emirats arabes unis        GBR   \n",
       "2            Afghanistan          afghanistan              \n",
       "3                Albania              albanie        TUR   \n",
       "4                 Angola               angola        PRT   \n",
       "5              Argentina            argentine        ESP   \n",
       "6                Austria             autriche              \n",
       "7              Australia            australie        GBR   \n",
       "9               Barbados              barbade        GBR   \n",
       "10            Bangladesh           bangladesh        GBR   \n",
       "\n",
       "                            filename         file_country  \n",
       "0                    andorre1993.txt              andorre  \n",
       "1   emirats-arabes-unis1971-1972.txt  emirats arabes unis  \n",
       "2                afghanistan2004.txt          afghanistan  \n",
       "3               albanie1998-2008.txt              albanie  \n",
       "4                     angola2010.txt               angola  \n",
       "5             argentine1853-1994.txt            argentine  \n",
       "6                   autriche1920.txt             autriche  \n",
       "7             australie1900-1977.txt            australie  \n",
       "9               barbade1966-2007.txt              barbade  \n",
       "10           bangladesh1972-2011.txt           bangladesh  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now `colonizer1` is a country code. Since the machine learning algorithm requires numeric values, we make a 0/1 binary variable `uk_col` which is 1 if `colonizer1 == \"GBR\"` and 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"uk_col\"] = (merged_df[\"colonizer1\"] == \"GBR\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "      <th>uk_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorre</td>\n",
       "      <td></td>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "      <td>emirats-arabes-unis1971-1972.txt</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albanie</td>\n",
       "      <td>TUR</td>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>angola</td>\n",
       "      <td>PRT</td>\n",
       "      <td>angola2010.txt</td>\n",
       "      <td>angola</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country                 pays colonizer1  \\\n",
       "0               Andorra              andorre              \n",
       "1  United Arab Emirates  emirats arabes unis        GBR   \n",
       "2           Afghanistan          afghanistan              \n",
       "3               Albania              albanie        TUR   \n",
       "4                Angola               angola        PRT   \n",
       "\n",
       "                           filename         file_country  uk_col  \n",
       "0                   andorre1993.txt              andorre       0  \n",
       "1  emirats-arabes-unis1971-1972.txt  emirats arabes unis       1  \n",
       "2               afghanistan2004.txt          afghanistan       0  \n",
       "3              albanie1998-2008.txt              albanie       0  \n",
       "4                    angola2010.txt               angola       0  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Machine Learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step towards the actual ML is to load the text of each constitution. To this end, we import Python's `codecs` library which just lets us specify the encoding of a text file (which is important when your text files might have \"non-standard\", for example non-Latin, characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just \"pull out\" the `filename` column of our dataset and put it into a standard Python list, for easy looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the list of texts\n",
    "file_list = merged_df[\"filename\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main text-loading loop. See comments therein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading andorre1993.txt\n",
      "Loading emirats-arabes-unis1971-1972.txt\n",
      "Loading afghanistan2004.txt\n",
      "Loading albanie1998-2008.txt\n",
      "Loading angola2010.txt\n",
      "Loading argentine1853-1994.txt\n",
      "Loading autriche1920.txt\n",
      "Loading australie1900-1977.txt\n",
      "Loading barbade1966-2007.txt\n",
      "Loading bangladesh1972-2011.txt\n",
      "Loading bulgarie1991-2007.txt\n",
      "Loading burundi2005.txt\n",
      "Loading bolivie2009.txt\n",
      "Loading bahamas1973.txt\n",
      "Loading bhoutan2008.txt\n",
      "Loading botswana_1996.txt\n",
      "Loading belize1981-2010.txt\n",
      "Loading canada1867-1982.txt\n",
      "Loading suisse1999-2011.txt\n",
      "Loading chili1980-2012.txt\n",
      "Loading cameroun1972-1996.txt\n",
      "Loading chine1982-2004.txt\n",
      "Loading colombie1991-2011.txt\n",
      "Loading cuba1976-2003.txt\n",
      "Loading chypre1960-1996.txt\n",
      "Loading allemagne1949-2010.txt\n",
      "Loading djibouti1992-2010.txt\n",
      "Loading danemark1953.txt\n",
      "Loading dominique1978-1984.txt\n",
      "Loading equateur2008.txt\n",
      "Loading estonie1992-2007.txt\n",
      "Loading egypte2011.txt\n",
      "Loading espagne1978-2011.txt\n",
      "Loading ethiopie1995.txt\n",
      "Loading finlande1999-2011.txt\n",
      "Loading fidji1990-1997.txt\n",
      "Loading france1958-2008.txt\n",
      "Loading gabon1991-2003.txt\n",
      "Loading grenade1973.txt\n",
      "Loading ghana1992.txt\n",
      "Loading gambie1996-2001.txt\n",
      "Loading guatemala1985-1986-1993.txt\n",
      "Loading guyana1980-2007.txt\n",
      "Loading honduras1982-1991.txt\n",
      "Loading croatie1990-2010.txt\n",
      "Loading hongrie2011.txt\n",
      "Loading irlande1937-2011.txt\n",
      "Loading inde1949-1950-2011.txt\n",
      "Loading iran1979-1989.txt\n",
      "Loading islande1944-1999.txt\n",
      "Loading italie1947-2007.txt\n",
      "Loading jordanie1952-1984.txt\n",
      "Loading japon1946.txt\n",
      "Loading kenya2010.txt\n",
      "Loading kirghizistan2010.txt\n",
      "Loading cambodge1993-2008.txt\n",
      "Loading kiribati1979.txt\n",
      "Loading comores2001-2009.txt\n",
      "Loading liban1926-1990.txt\n",
      "Loading sri-lanka1978-2001.txt\n",
      "Loading lesotho1993.txt\n",
      "Loading lituanie1992-2006.txt\n",
      "Loading luxembourg1868-2009.txt\n",
      "Loading lettonie1922-2009.txt\n",
      "Loading libye2011.txt\n",
      "Loading maroc2011.txt\n",
      "Loading moldavie19942006.txt\n",
      "Loading madagascar2010.txt\n",
      "Loading marshall19791995.txt\n",
      "Loading mali1992.txt\n",
      "Loading mauritanie19912012.txt\n",
      "Loading malte196642007.txt\n",
      "Loading maurice19682003.txt\n",
      "Loading maldives2008.txt\n",
      "Loading malawi1194-1999.txt\n",
      "Loading mexique19172012.txt\n",
      "Loading malaisie1963-2006.txt\n",
      "Loading mozambique2004-2007.txt\n",
      "Loading namibie1990-2010.txt\n",
      "Loading niger2010.txt\n",
      "Loading nicaragua1987.txt\n",
      "Loading nauru1968-1968.txt\n",
      "Loading oman1996.txt\n",
      "Loading panama1972-2004.txt\n",
      "Loading philippines1987.txt\n",
      "Loading pakistan19732012.txt\n",
      "Loading pologne1997-2009.txt\n",
      "Loading portugal1976.txt\n",
      "Loading paraguay1992-2011.txt\n",
      "Loading qatar2004.txt\n",
      "Loading roumanie1991-2003.txt\n",
      "Loading russie1993-2008.txt\n",
      "Loading rwanda2003-2010.txt\n",
      "Loading arabie-saoudite1992.txt\n",
      "Loading seychelles1993-2011.txt\n",
      "Loading soudan2005.txt\n",
      "Loading singapour1963-2010.txt\n",
      "Loading slovaquie1992-2006.txt\n",
      "Loading sierra-leone1991.txt\n",
      "Loading somalie1979.txt\n",
      "Loading suriname1987-1992.txt\n",
      "Loading syrie1973-2012.txt\n",
      "Loading swaziland2005.txt\n",
      "Loading tchad1996-2005.txt\n",
      "Loading togo1992-2007.txt\n",
      "Loading tadjikistan1994-2003.txt\n",
      "Loading tunisie1959-2008.txt\n",
      "Loading tonga1875-1988.txt\n",
      "Loading timor-oriental2002.txt\n",
      "Loading turquie1982-2011.txt\n",
      "Loading tuvalu1986-2007.txt\n",
      "Loading tanzanie1977.txt\n",
      "Loading ukraine1996-2010.txt\n",
      "Loading ouganda19952005.txt\n",
      "Loading uruguay1967-2004.txt\n",
      "Loading venezuela1999-2009.txt\n",
      "Loading vanuatu1980-1983.txt\n",
      "Loading samoa1960-2008.txt\n",
      "Loading zambie1991-1996.txt\n",
      "Loading zimbabwe1979-2009.txt\n"
     ]
    }
   ],
   "source": [
    "# text_list will be filled with the contents of each constitution\n",
    "text_list = []\n",
    "# This loops over all filenames in file_list,\n",
    "# storing them into cur_filename for use inside the loop\n",
    "for cur_filename in file_list:\n",
    "    print(\"Loading \" + cur_filename)\n",
    "    # os.path.join() is just a handy function which uses the correct type of slash in a\n",
    "    # file path, since Windows uses backslashes like C:\\cool.txt, whereas OSX and Linux\n",
    "    # use forward slashes like /home/cool.txt\n",
    "    cur_filepath = os.path.join(\"constitutions\",cur_filename)\n",
    "    # Here's where we use codecs.open(). The arguments are: filename, mode (\"r\" means\n",
    "    # \"read the file\"), encoding (\"utf-8\" is a standard Unicode text format), and\n",
    "    # errors, which tells it to just skip any reading errors (for example, characters\n",
    "    # it doesn't recognize) rather than crashing the code\n",
    "    with codecs.open(cur_filepath, \"r\", \"utf-8\", errors=\"ignore\") as f:\n",
    "        # We replace the \\n and \\r which are just line breaks, so that we just get\n",
    "        # the file contents as a single, unbroken string\n",
    "        cur_text = f.read().replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "        text_list.append(cur_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure it worked, we look at the first 500 characters of the 4th constitution in the list (remember that computers count starting with zero, so `text_list[3]` gives the 4th element in `text_list`), which happens to be Albania's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CONSTITUTION OF ALBANIA     We, the people of Albania, proud and aware of our history, with responsibility for   the future, and with faith in God and/or other universal values, with determination   to build a social and democratic state based on the rule of law, and to guarantee   the fundamental human rights and freedoms, with a spirit of religious coexistence   and tolerance, with a pledge to protect human dignity and personhood, as well as   for the prosperity of the whole nation, for peace,'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list[3][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this Python `text_list` variable, we can insert it into our Pandas DataFrame as a new column in `merged_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now make each text a cell within the DataFrame\n",
    "merged_df[\"const_text\"] = text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "      <th>uk_col</th>\n",
       "      <th>const_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorre</td>\n",
       "      <td></td>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "      <td>0</td>\n",
       "      <td>Constitution of the Principality of Andorra   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "      <td>emirats-arabes-unis1971-1972.txt</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>1</td>\n",
       "      <td>United Arab Emirates  THE PROVISIONAL CONSTITU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>The Constitution of Afghanistan     January 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albanie</td>\n",
       "      <td>TUR</td>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "      <td>0</td>\n",
       "      <td>CONSTITUTION OF ALBANIA     We, the people of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>angola</td>\n",
       "      <td>PRT</td>\n",
       "      <td>angola2010.txt</td>\n",
       "      <td>angola</td>\n",
       "      <td>0</td>\n",
       "      <td>REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country                 pays colonizer1  \\\n",
       "0               Andorra              andorre              \n",
       "1  United Arab Emirates  emirats arabes unis        GBR   \n",
       "2           Afghanistan          afghanistan              \n",
       "3               Albania              albanie        TUR   \n",
       "4                Angola               angola        PRT   \n",
       "\n",
       "                           filename         file_country  uk_col  \\\n",
       "0                   andorre1993.txt              andorre       0   \n",
       "1  emirats-arabes-unis1971-1972.txt  emirats arabes unis       1   \n",
       "2               afghanistan2004.txt          afghanistan       0   \n",
       "3              albanie1998-2008.txt              albanie       0   \n",
       "4                    angola2010.txt               angola       0   \n",
       "\n",
       "                                          const_text  \n",
       "0  Constitution of the Principality of Andorra   ...  \n",
       "1  United Arab Emirates  THE PROVISIONAL CONSTITU...  \n",
       "2  The Constitution of Afghanistan     January 3,...  \n",
       "3  CONSTITUTION OF ALBANIA     We, the people of ...  \n",
       "4  REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I could do a whole tutorial on Gensim, since imo it's the best text-processing library in Python. But really we don't need to do much fancy text processing here, so I'll just use it to auto-preprocess each constitution via the `preprocess_string()` function, which does things like lowercasing, removing overly-common words like \"the\", stemming, and other important cleaning operations. The full list of stuff it does is [here](https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string), and you should def check out Gensim more generally. My favorite list of tutorials for it is [here](https://github.com/RaRe-Technologies/gensim/blob/develop/tutorials.md).\n",
    "\n",
    "Syntax-wise, we make a new variable in our DataFrame called `const_preproc` by applying (via the `.apply()` function) `preprocess_string` to each cell in the `const_text` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "merged_df[\"const_preproc\"] = merged_df[\"const_text\"].apply(preprocess_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only issue with `preprocess_string()` is that it spits out the processed string as a list of words. So to re-format it as a string, we just put a space in between each spat-out word using Python's `join()` function. Here instead of calling `apply()` with an entire separate function, we just make a \"mini-function\" called a *Lambda function*, which here just says take `x` (the list of words) and join each element together with a space. (In general, `lambda x: <code involving x>` just tells python \"take x and perform this code on it\", which is convenient in the sense that we don't have to explicitly define a whole new function for simple operations like this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"const_preproc\"] = merged_df[\"const_preproc\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "      <th>uk_col</th>\n",
       "      <th>const_text</th>\n",
       "      <th>const_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorre</td>\n",
       "      <td></td>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "      <td>0</td>\n",
       "      <td>Constitution of the Principality of Andorra   ...</td>\n",
       "      <td>constitut princip andorra consel gener princip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "      <td>emirats-arabes-unis1971-1972.txt</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>1</td>\n",
       "      <td>United Arab Emirates  THE PROVISIONAL CONSTITU...</td>\n",
       "      <td>unit arab emir provision constitut unit arab e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>The Constitution of Afghanistan     January 3,...</td>\n",
       "      <td>constitut afghanistan januari god graciou merc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albanie</td>\n",
       "      <td>TUR</td>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "      <td>0</td>\n",
       "      <td>CONSTITUTION OF ALBANIA     We, the people of ...</td>\n",
       "      <td>constitut albania peopl albania proud awar his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>angola</td>\n",
       "      <td>PRT</td>\n",
       "      <td>angola2010.txt</td>\n",
       "      <td>angola</td>\n",
       "      <td>0</td>\n",
       "      <td>REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...</td>\n",
       "      <td>republ angola nation assembl constitu assembl ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country                 pays colonizer1  \\\n",
       "0               Andorra              andorre              \n",
       "1  United Arab Emirates  emirats arabes unis        GBR   \n",
       "2           Afghanistan          afghanistan              \n",
       "3               Albania              albanie        TUR   \n",
       "4                Angola               angola        PRT   \n",
       "\n",
       "                           filename         file_country  uk_col  \\\n",
       "0                   andorre1993.txt              andorre       0   \n",
       "1  emirats-arabes-unis1971-1972.txt  emirats arabes unis       1   \n",
       "2               afghanistan2004.txt          afghanistan       0   \n",
       "3              albanie1998-2008.txt              albanie       0   \n",
       "4                    angola2010.txt               angola       0   \n",
       "\n",
       "                                          const_text  \\\n",
       "0  Constitution of the Principality of Andorra   ...   \n",
       "1  United Arab Emirates  THE PROVISIONAL CONSTITU...   \n",
       "2  The Constitution of Afghanistan     January 3,...   \n",
       "3  CONSTITUTION OF ALBANIA     We, the people of ...   \n",
       "4  REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...   \n",
       "\n",
       "                                       const_preproc  \n",
       "0  constitut princip andorra consel gener princip...  \n",
       "1  unit arab emir provision constitut unit arab e...  \n",
       "2  constitut afghanistan januari god graciou merc...  \n",
       "3  constitut albania peopl albania proud awar his...  \n",
       "4  republ angola nation assembl constitu assembl ...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as a first foray into machine learning, we're just going to construct four extremely simple \"features\" which we think can help the algorithm predict whether or not the constitution is that of a former UK colony or not. Our first feature is simply the length of the constitution (in terms of number of words). To construct this feature, we use `.apply()` again, calling Python's `len()` function on a version of the `const_preproc` cell split into separate words via `split()`, and store the length into a new `const_len` column in our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"const_len\"] = merged_df[\"const_preproc\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "      <th>uk_col</th>\n",
       "      <th>const_text</th>\n",
       "      <th>const_preproc</th>\n",
       "      <th>const_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorre</td>\n",
       "      <td></td>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "      <td>0</td>\n",
       "      <td>Constitution of the Principality of Andorra   ...</td>\n",
       "      <td>constitut princip andorra consel gener princip...</td>\n",
       "      <td>4492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "      <td>emirats-arabes-unis1971-1972.txt</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>1</td>\n",
       "      <td>United Arab Emirates  THE PROVISIONAL CONSTITU...</td>\n",
       "      <td>unit arab emir provision constitut unit arab e...</td>\n",
       "      <td>5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>The Constitution of Afghanistan     January 3,...</td>\n",
       "      <td>constitut afghanistan januari god graciou merc...</td>\n",
       "      <td>5390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albanie</td>\n",
       "      <td>TUR</td>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "      <td>0</td>\n",
       "      <td>CONSTITUTION OF ALBANIA     We, the people of ...</td>\n",
       "      <td>constitut albania peopl albania proud awar his...</td>\n",
       "      <td>6197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>angola</td>\n",
       "      <td>PRT</td>\n",
       "      <td>angola2010.txt</td>\n",
       "      <td>angola</td>\n",
       "      <td>0</td>\n",
       "      <td>REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...</td>\n",
       "      <td>republ angola nation assembl constitu assembl ...</td>\n",
       "      <td>13634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>argentine</td>\n",
       "      <td>ESP</td>\n",
       "      <td>argentine1853-1994.txt</td>\n",
       "      <td>argentine</td>\n",
       "      <td>0</td>\n",
       "      <td>ï»¿                        CONSTITUTION  OF  THE...</td>\n",
       "      <td>constitut argentin nation preambl repres peopl...</td>\n",
       "      <td>6072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austria</td>\n",
       "      <td>autriche</td>\n",
       "      <td></td>\n",
       "      <td>autriche1920.txt</td>\n",
       "      <td>autriche</td>\n",
       "      <td>0</td>\n",
       "      <td>Erste...</td>\n",
       "      <td>erst hauptstiick chapter allgemein bestimmunge...</td>\n",
       "      <td>54203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Australia</td>\n",
       "      <td>australie</td>\n",
       "      <td>GBR</td>\n",
       "      <td>australie1900-1977.txt</td>\n",
       "      <td>australie</td>\n",
       "      <td>1</td>\n",
       "      <td>ï»¿          AUSTRALIA         Commonwealth  of ...</td>\n",
       "      <td>australia commonwealth australia constitut act...</td>\n",
       "      <td>7247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>barbade</td>\n",
       "      <td>GBR</td>\n",
       "      <td>barbade1966-2007.txt</td>\n",
       "      <td>barbade</td>\n",
       "      <td>1</td>\n",
       "      <td>The Constitution of Barbados     ARRANGEIV1E...</td>\n",
       "      <td>constitut barbado arrangeiv section section ch...</td>\n",
       "      <td>13690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>GBR</td>\n",
       "      <td>bangladesh1972-2011.txt</td>\n",
       "      <td>bangladesh</td>\n",
       "      <td>1</td>\n",
       "      <td>(In the name of Allah, the Beneficient, th...</td>\n",
       "      <td>allah benefici merci creator merci preambl peo...</td>\n",
       "      <td>9822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country                 pays colonizer1  \\\n",
       "0                Andorra              andorre              \n",
       "1   United Arab Emirates  emirats arabes unis        GBR   \n",
       "2            Afghanistan          afghanistan              \n",
       "3                Albania              albanie        TUR   \n",
       "4                 Angola               angola        PRT   \n",
       "5              Argentina            argentine        ESP   \n",
       "6                Austria             autriche              \n",
       "7              Australia            australie        GBR   \n",
       "9               Barbados              barbade        GBR   \n",
       "10            Bangladesh           bangladesh        GBR   \n",
       "\n",
       "                            filename         file_country  uk_col  \\\n",
       "0                    andorre1993.txt              andorre       0   \n",
       "1   emirats-arabes-unis1971-1972.txt  emirats arabes unis       1   \n",
       "2                afghanistan2004.txt          afghanistan       0   \n",
       "3               albanie1998-2008.txt              albanie       0   \n",
       "4                     angola2010.txt               angola       0   \n",
       "5             argentine1853-1994.txt            argentine       0   \n",
       "6                   autriche1920.txt             autriche       0   \n",
       "7             australie1900-1977.txt            australie       1   \n",
       "9               barbade1966-2007.txt              barbade       1   \n",
       "10           bangladesh1972-2011.txt           bangladesh       1   \n",
       "\n",
       "                                           const_text  \\\n",
       "0   Constitution of the Principality of Andorra   ...   \n",
       "1   United Arab Emirates  THE PROVISIONAL CONSTITU...   \n",
       "2   The Constitution of Afghanistan     January 3,...   \n",
       "3   CONSTITUTION OF ALBANIA     We, the people of ...   \n",
       "4   REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...   \n",
       "5   ï»¿                        CONSTITUTION  OF  THE...   \n",
       "6                                            Erste...   \n",
       "7   ï»¿          AUSTRALIA         Commonwealth  of ...   \n",
       "9     The Constitution of Barbados     ARRANGEIV1E...   \n",
       "10      (In the name of Allah, the Beneficient, th...   \n",
       "\n",
       "                                        const_preproc  const_len  \n",
       "0   constitut princip andorra consel gener princip...       4492  \n",
       "1   unit arab emir provision constitut unit arab e...       5329  \n",
       "2   constitut afghanistan januari god graciou merc...       5390  \n",
       "3   constitut albania peopl albania proud awar his...       6197  \n",
       "4   republ angola nation assembl constitu assembl ...      13634  \n",
       "5   constitut argentin nation preambl repres peopl...       6072  \n",
       "6   erst hauptstiick chapter allgemein bestimmunge...      54203  \n",
       "7   australia commonwealth australia constitut act...       7247  \n",
       "9   constitut barbado arrangeiv section section ch...      13690  \n",
       "10  allah benefici merci creator merci preambl peo...       9822  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last three features are the proportion of the words in the constitution which are \"freedom\", \"justice\", and \"liberty\". Since the `preprocess_string()` function we called from Gensim performs stemming on all the words, we shorten these to their stems (\"free\", \"just\", \"liber\") to make sure we're getting the correct counts. Then we just take the counts and divide by `const_len` to get the proportions for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"num_free\"] = merged_df[\"const_preproc\"].str.count(\"free\")\n",
    "merged_df[\"num_just\"] = merged_df[\"const_preproc\"].str.count(\"just\")\n",
    "merged_df[\"num_lib\"] = merged_df[\"const_preproc\"].str.count(\"liber\")\n",
    "merged_df[\"prop_free\"] = merged_df[\"num_free\"] / merged_df[\"const_len\"]\n",
    "merged_df[\"prop_just\"] = merged_df[\"num_just\"] / merged_df[\"const_len\"]\n",
    "merged_df[\"prop_lib\"] = merged_df[\"num_lib\"] / merged_df[\"const_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>pays</th>\n",
       "      <th>colonizer1</th>\n",
       "      <th>filename</th>\n",
       "      <th>file_country</th>\n",
       "      <th>uk_col</th>\n",
       "      <th>const_text</th>\n",
       "      <th>const_preproc</th>\n",
       "      <th>const_len</th>\n",
       "      <th>num_free</th>\n",
       "      <th>num_just</th>\n",
       "      <th>num_lib</th>\n",
       "      <th>prop_free</th>\n",
       "      <th>prop_just</th>\n",
       "      <th>prop_lib</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>andorre</td>\n",
       "      <td></td>\n",
       "      <td>andorre1993.txt</td>\n",
       "      <td>andorre</td>\n",
       "      <td>0</td>\n",
       "      <td>Constitution of the Principality of Andorra   ...</td>\n",
       "      <td>constitut princip andorra consel gener princip...</td>\n",
       "      <td>4492</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>GBR</td>\n",
       "      <td>emirats-arabes-unis1971-1972.txt</td>\n",
       "      <td>emirats arabes unis</td>\n",
       "      <td>1</td>\n",
       "      <td>United Arab Emirates  THE PROVISIONAL CONSTITU...</td>\n",
       "      <td>unit arab emir provision constitut unit arab e...</td>\n",
       "      <td>5329</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.001314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td></td>\n",
       "      <td>afghanistan2004.txt</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>The Constitution of Afghanistan     January 3,...</td>\n",
       "      <td>constitut afghanistan januari god graciou merc...</td>\n",
       "      <td>5390</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>albanie</td>\n",
       "      <td>TUR</td>\n",
       "      <td>albanie1998-2008.txt</td>\n",
       "      <td>albanie</td>\n",
       "      <td>0</td>\n",
       "      <td>CONSTITUTION OF ALBANIA     We, the people of ...</td>\n",
       "      <td>constitut albania peopl albania proud awar his...</td>\n",
       "      <td>6197</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007907</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>angola</td>\n",
       "      <td>PRT</td>\n",
       "      <td>angola2010.txt</td>\n",
       "      <td>angola</td>\n",
       "      <td>0</td>\n",
       "      <td>REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...</td>\n",
       "      <td>republ angola nation assembl constitu assembl ...</td>\n",
       "      <td>13634</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                country                 pays colonizer1  \\\n",
       "0               Andorra              andorre              \n",
       "1  United Arab Emirates  emirats arabes unis        GBR   \n",
       "2           Afghanistan          afghanistan              \n",
       "3               Albania              albanie        TUR   \n",
       "4                Angola               angola        PRT   \n",
       "\n",
       "                           filename         file_country  uk_col  \\\n",
       "0                   andorre1993.txt              andorre       0   \n",
       "1  emirats-arabes-unis1971-1972.txt  emirats arabes unis       1   \n",
       "2               afghanistan2004.txt          afghanistan       0   \n",
       "3              albanie1998-2008.txt              albanie       0   \n",
       "4                    angola2010.txt               angola       0   \n",
       "\n",
       "                                          const_text  \\\n",
       "0  Constitution of the Principality of Andorra   ...   \n",
       "1  United Arab Emirates  THE PROVISIONAL CONSTITU...   \n",
       "2  The Constitution of Afghanistan     January 3,...   \n",
       "3  CONSTITUTION OF ALBANIA     We, the people of ...   \n",
       "4  REPUBLIC OF ANGOLA   NATIONAL ASSEMBLY     CON...   \n",
       "\n",
       "                                       const_preproc  const_len  num_free  \\\n",
       "0  constitut princip andorra consel gener princip...       4492        31   \n",
       "1  unit arab emir provision constitut unit arab e...       5329        15   \n",
       "2  constitut afghanistan januari god graciou merc...       5390        16   \n",
       "3  constitut albania peopl albania proud awar his...       6197        49   \n",
       "4  republ angola nation assembl constitu assembl ...      13634       100   \n",
       "\n",
       "   num_just  num_lib  prop_free  prop_just  prop_lib  \n",
       "0        31        5   0.006901   0.006901  0.001113  \n",
       "1         8        7   0.002815   0.001501  0.001314  \n",
       "2        16        5   0.002968   0.002968  0.000928  \n",
       "3        20        9   0.007907   0.003227  0.001452  \n",
       "4        32        8   0.007335   0.002347  0.000587  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can import our machine learning library, [Scikit-Learn](http://scikit-learn.org/stable/). First we import its `train_test_split()` function, which allows us to divide the data up into training and test sets in a consistent manner (by seeding it using the `random_state` argument). The training set is what the machine learning algorithm will use to try and *learn* a relationship between the features and the outcome variable (`uk_col`), and then its success in this learning will be measured by how well it can predict the outcome variable for the texts in the *test* set. Here we randomly select 80% of the observations to be training data and 20% to be test data, using the `test_size` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test data [by splitting the indices]\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 96\n",
      "Test size: 24\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size: \" + str(len(train_df)))\n",
    "print(\"Test size: \" + str(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split our data, we can \"pull out\" just the relevant columns of our DataFrame, to produce the training features, training labels (\"label\" is just an ML term for the outcome variable we're trying to predict), test features, and test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variables we want to \"pull out\" of the DataFrame to use as features\n",
    "feature_vars = [\"const_len\",\"prop_free\",\"prop_just\",\"prop_lib\"]\n",
    "# The variable we want to \"pull out\" of the DataFrame to use as the outcome variable\n",
    "# (which the ML algorithm will try to predict)\n",
    "label_var = \"uk_col\"\n",
    "\n",
    "train_features = train_df[feature_vars]\n",
    "train_labels = train_df[label_var]\n",
    "test_features = test_df[feature_vars]\n",
    "# Since the ML algorithm will never look at the test labels anyways,\n",
    "# I convert them to a Python list for easier use later on\n",
    "test_labels = test_df[label_var].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the moment we've all been waiting for, the actual machine learning. I'm using the most simple of all possible algorithms here, [Multinomial Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) with two classes (so really Binomial Naive Bayes), which works ridiculously fast because it makes the (incorrect) assumption that all features are independent. In our case, for example, it's probably not true that the number of times \"freedom\" appears is independent of the number of times \"liberty\" appears. But it turns out that Naive Bayes does astonishingly well despite this simplifying assumption, and for large datasets it's sometimes the case that it's the only algorithm that will run in a reasonable amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual test labels: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "6 mislabeled obs out of 24 total test observations\n",
      "Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# I'm writing these as functions so that we can re-run the procedure with different\n",
    "# sets of features, which we'll do below.\n",
    "def evaluateAccuracy(predicted_labels, actual_labels):\n",
    "    num_test_obs = len(actual_labels)\n",
    "    num_mislabeled = (predicted_labels != actual_labels).sum()\n",
    "    accuracy = 1 - (num_mislabeled/num_test_obs)\n",
    "    print(str(num_mislabeled) + \" mislabeled obs out of \" + \n",
    "          str(num_test_obs) + \" total test observations\")\n",
    "    print(\"Accuracy = \" + str(accuracy))\n",
    "    \n",
    "def naiveBayesClassify(train_features, train_labels, test_features, test_labels):\n",
    "    gnb = MultinomialNB()\n",
    "    # This is where all the magic happens. Calling .fit() makes the ML algorithm\n",
    "    # look at the training data to try and learn a relationship, and then calling\n",
    "    # .predict() asks it to make predictions using that learned relationship, which\n",
    "    # get stored into y_pred\n",
    "    y_pred = gnb.fit(train_features, train_labels).predict(test_features)\n",
    "    print(\"Predicted labels: \" + str(y_pred))\n",
    "    print(\"Actual test labels: \" + str(test_labels))\n",
    "    evaluateAccuracy(y_pred, test_labels)\n",
    "    return gnb\n",
    "    \n",
    "hand_engineered = naiveBayesClassify(train_features, train_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get a score of 75%. Is this good? We'll find out below. For now, just keep it in mind and we'll see if we can do better. To this end, we're going to try massively expanding the feature set by using $n$-gram features. An [$n$-gram](https://en.wikipedia.org/wiki/N-gram) is just an ordered sequence of $n$ words. For example, within the phrase \"machine learning is fun\" we have the $1$-grams \"machine\", \"learning\", \"is\", \"fun\", the $2$-grams \"machine learning\", \"learning is\", and \"is fun\", and the $3$-grams \"machine learning is\" and \"learning is fun\". So, instead of trying to \"guess\" words that will be predictive of UK colony status, let's just throw in counts of ALL words across ALL the constitutions, and let the ML algorithm *figure out* which ones are important.\n",
    "\n",
    "Scikit-Learn provides a super easy-to-use class called `CountVectorizer`, which just takes in a list of strings and spits out $n$-gram counts which are immediately ready to be used as input features for an ML algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note here: the `.fit_transform()` function first scans over all the strings and figures out how big the feature vector of word counts needs to be, and then scans a second time to \"fill in\" the vector for each string. We *don't*, however, want to call `.fit_transform()` a second time for the test data, if you think about it, because we need the training and test vectors to be the same size, but there are probably different sets of words in the training and test data. So when generating the vectors for the *test* data, we just call `.transform()`, which skips the step of figuring out the \"indices\" of the vector and just produces word counts for the set of words we learned from the *training* data via `fit_transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = count_vect.fit_transform(train_df[\"const_preproc\"]).toarray()\n",
    "test_counts = count_vect.transform(test_df[\"const_preproc\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 17177)\n",
      "(24, 17177)\n"
     ]
    }
   ],
   "source": [
    "print(train_counts.shape)\n",
    "print(test_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above numbers mean that the training data consists of 96 rows with word counts for 17,177 separate words, while the test data consists of 24 rows with word counts for the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Actual test labels: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "3 mislabeled obs out of 24 total test observations\n",
      "Accuracy = 0.875\n"
     ]
    }
   ],
   "source": [
    "ngram_classifier = naiveBayesClassify(train_counts, train_labels, test_counts, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now with this additional information, the algorithm is able to get 87.5% of its predictions correct! Again we should ask: is this actually good? Now we'll find out.\n",
    "\n",
    "To find out, we basically want to compare the accuracy from the ML output with the accuracy we'd get by doing \"dumb\" things, like randomly guessing or always guessing yes/no. If the ML algorithm gets higher accuracy than the accuracy of these approaches, we can say that in a sense the algorithm is actually learning something, that's it's actually doing something smart.\n",
    "\n",
    "Here I introduce the Python library `numpy` (which actually is what Pandas and Scikit-Learn have been using \"under the hood\" anyways), which contains a `np.array()` data type that \"works nicely\" with Pandas/Scikit-Learn data, and also has random number generation functions like `np.random.choice()` which we use below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Just \"seeding\" the random number generator so my results are comparable with yours.\n",
    "# (Otherwise it uses the time, so you get different results based on what time you run it)\n",
    "np.random.seed(42)\n",
    "# Baseline 1: random guessing\n",
    "random_test_labels = np.random.choice([0,1], size=(len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 mislabeled obs out of 24 total test observations\n",
      "Accuracy = 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "evaluateAccuracy(random_test_labels, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know: the four \"hand-engineered\" features we made only do sligtly better than random guessing, whereas the $n$-gram features do significantly better.\n",
    "\n",
    "Next we examine the accuracy of always-guess-yes and always-guess-no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of 1s the same size as the test data\n",
    "always_yes = np.array([1]*len(test_df))\n",
    "# And same with a list of 0s\n",
    "always_no = np.array([0]*len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 mislabeled obs out of 24 total test observations\n",
      "Accuracy = 0.25\n"
     ]
    }
   ],
   "source": [
    "evaluateAccuracy(always_yes, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 mislabeled obs out of 24 total test observations\n",
      "Accuracy = 0.75\n"
     ]
    }
   ],
   "source": [
    "evaluateAccuracy(always_no, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that in fact the hand-engineered features performed WORSE than a \"dumb\" approach -- namely, always guessing \"no, not a UK colony\". The run using the $n$-gram features, therefore, is the only one for which we can say with confidence that the ML algorithm is doing something smart.\n",
    "\n",
    "In conclusion, it's important to know what your *baseline* performance is -- i.e., how well you can do with dumb approaches like random guessing or always guessing yes/no -- before drawing conclusions about how well your method is doing.\n",
    "\n",
    "The real \"correct\" thing to report when evaluating an ML algorithm is actually not accuracy at all, but rather [F1 score](https://en.wikipedia.org/wiki/F1_score). It takes into account what we learned by looking at the always-no and always-yes classifiers, and weights the accuracy based on false negatives and false positives.\n",
    "\n",
    "We could probably get even better performance by using not only 1-grams (aka words) but also 2-grams and 3-grams here. I'll leave it up to you to figure out how to expand the feature set to include these higher-order $n$-grams, but as a hint it should only require adding a single argument to the `CountVectorizer()` call...\n",
    "\n",
    "As a last thing (which really would be a central thing for social science, but I'm trying to make this quick and just show the basic things you can do), let's look at which features were most \"informative\" for the (better than random/\"dumb\" guessing) $n$-gram classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shamelessly stolen from\n",
    "# https://stackoverflow.com/questions/26976362/how-to-get-most-informative-features-for-scikit-learn-classifier-for-different-c\n",
    "def mostInformative(vectorizer, classifier, n=10):\n",
    "    labelid = list(classifier.classes_).index(0)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn = sorted(zip(classifier.coef_[labelid], feature_names))[-n:]\n",
    "    topn.reverse()\n",
    "    for coef, feat in topn:\n",
    "        print(feat, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shall -3.21323717541\n",
      "person -3.92419641785\n",
      "offic -4.04265700621\n",
      "law -4.25126659155\n",
      "constitut -4.30042631298\n",
      "court -4.30795358523\n",
      "member -4.36271328139\n",
      "presid -4.36621984225\n",
      "parliament -4.43770482669\n",
      "act -4.6574208148\n"
     ]
    }
   ],
   "source": [
    "mostInformative(count_vect, ngram_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretations abound! Try it on your own text corpora! The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
